{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training_v05 \n",
    "\n",
    "To be filled later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO> TensorFlow version: 1.14.0\n",
      "INFO> Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "import subprocess\n",
    "import datetime\n",
    "import numpy\n",
    "import sklearn.metrics\n",
    "import tensorflow\n",
    "\n",
    "print(\"INFO> TensorFlow version: %s\" % tensorflow.__version__)\n",
    "print(\"INFO> Num GPUs Available: \", len(tensorflow.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO> Reading file config.yam from directory: /raid5/disk1/mlproj10/classification\n",
      "INFO> checkDataset   : True\n",
      "INFO> imageHeight    : 720\n",
      "INFO> trnDir         : /home/jmv/data/mlproj10/dataset/trn\n",
      "INFO> nValSamples    : 671\n",
      "INFO> imageWidth     : 1280\n",
      "INFO> nTrnSamples    : 2000\n",
      "INFO> learningRate   : 1e-6\n",
      "INFO> createDataset  : True\n",
      "INFO> batchSize      : 16\n",
      "INFO> logDir         : /home/jmv/data/mlproj10/log/\n",
      "INFO> tstDir         : /home/jmv/data/mlproj10/dataset/tst\n",
      "INFO> nTstSamples    : 671\n",
      "INFO> nEpochs        : 1000\n",
      "INFO> tmpDir         : /home/jmv/data/mlproj10/dataset/tmp\n",
      "INFO> remDir         : /home/jmv/data/mlproj10/dataset/rem\n",
      "INFO> checkpointDir  : /home/jmv/data/mlproj10/tmp/\n",
      "INFO> valDir         : /home/jmv/data/mlproj10/dataset/val\n"
     ]
    }
   ],
   "source": [
    "# Read parameters from local config.yaml file, and update corresponding Python variables\n",
    "currentDir = os.getcwd()\n",
    "print(\"INFO> Reading file config.yam from directory: %s\" %currentDir)\n",
    "yamlFile = open('config.yaml','r')\n",
    "yamlData = yaml.load(yamlFile,Loader=yaml.Loader)\n",
    "\n",
    "for key in sorted(yamlData):\n",
    "    print(\"INFO> %-15s: %s\" % (key,yamlData[key]))\n",
    "    \n",
    "imageWidth, imageHeight = yamlData['imageWidth'], yamlData['imageHeight']\n",
    "tmpDir = yamlData['tmpDir']\n",
    "trnDir = yamlData['trnDir']\n",
    "valDir = yamlData['valDir']\n",
    "tstDir = yamlData['tstDir']\n",
    "remDir = yamlData['remDir']\n",
    "nTrnSamples = yamlData['nTrnSamples']\n",
    "nValSamples = yamlData['nValSamples']\n",
    "nTstSamples = yamlData['nTstSamples']\n",
    "nEpochs = yamlData['nEpochs']\n",
    "batchSize = yamlData['batchSize']\n",
    "learningRate = float(yamlData['learningRate'])\n",
    "checkpointDir = yamlData['checkpointDir']\n",
    "logDir = yamlData['logDir']\n",
    "createDataset = yamlData['createDataset']\n",
    "checkDataset = yamlData['checkDataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Optionally run scripts to create dataset from golden data set & check the newly created dataset\n",
    "if createDataset:\n",
    "    cmd = 'rm -r -f dataset'\n",
    "    !{cmd}\n",
    "    cmd = './create_dataset.sh'\n",
    "    !{cmd}\n",
    "    %run randomize_and_copy_dataset_v04.ipynb\n",
    "\n",
    "if checkDataset:\n",
    "    cmd = './check_dataset.sh'\n",
    "    !{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModelInput = tensorflow.keras.layers.Input(shape=(imageHeight,imageWidth,3))\n",
    "x = tensorflow.keras.layers.Conv2D(64, (3,3), activation=\"relu\")(myModelInput)\n",
    "x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "x = tensorflow.keras.layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2D(128, (3,3), activation=\"relu\")(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "x = tensorflow.keras.layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2D(192, (3,3), activation=\"relu\")(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "x = tensorflow.keras.layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2D(192, (3,3), activation=\"relu\")(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "x = tensorflow.keras.layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2D(192, (3,3), activation=\"relu\")(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "x = tensorflow.keras.layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2D(128, (3,3), activation=\"relu\")(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "x = tensorflow.keras.layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "\n",
    "x = tensorflow.keras.layers.Flatten()(x)\n",
    "x = tensorflow.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Dropout(0.25)(x)\n",
    "myModelOutput = tensorflow.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = tensorflow.keras.models.Model(inputs=myModelInput, outputs=myModelOutput)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "tensorflow.keras.optimizers.RMSprop(lr=learningRate) \n",
    "\n",
    "model.compile(loss=tensorflow.keras.losses.BinaryCrossentropy(),\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc']) # should be accuracy in TF2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JMV need to review code below - December 12, 2019\n",
    "trnDataGen = tensorflow.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "valDataGen = tensorflow.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "trnGenerator = trnDataGen.flow_from_directory(\n",
    "    trnDir,\n",
    "    target_size=(imageHeight,imageWidth),\n",
    "    batch_size=batchSize,\n",
    "    class_mode='binary')\n",
    "\n",
    "valGenerator = valDataGen.flow_from_directory(\n",
    "    valDir,\n",
    "    target_size=(imageHeight,imageWidth),\n",
    "    batch_size=batchSize,\n",
    "    class_mode='binary')\n",
    "\n",
    "timeNow = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "fullCheckpointDir = checkpointDir + timeNow + \"/\"\n",
    "os.mkdir(fullCheckpointDir)\n",
    "# need to replace acc by accuracy below when moving to TF2.0\n",
    "filePath = fullCheckpointDir + \"{epoch:05d}_{loss:.6f}_{acc:.6f}_{val_loss:.6f}_{val_acc:.6f}.h5\" \n",
    "checkpoint = tensorflow.keras.callbacks.ModelCheckpoint(filePath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
    "\n",
    "# profile_batch=0 required to solve a bug w/ Tensorboard according to \n",
    "#   https://github.com/tensorflow/tensorboard/issues/2412\n",
    "fullLogDir = logDir + timeNow\n",
    "tensorboardCallback = tensorflow.keras.callbacks.TensorBoard(log_dir=fullLogDir,profile_batch=0)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    trnGenerator,\n",
    "    steps_per_epoch=nTrnSamples // batchSize,\n",
    "    epochs=nEpochs,\n",
    "    validation_data=valGenerator,\n",
    "    validation_steps=nValSamples // batchSize,\n",
    "    callbacks=[tensorboardCallback,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look in the tmp directory and select best model candidate based on train/val loss & accuracy\n",
    "# For TF1.14, added compile=False. This is not needed for TF2\n",
    "model = tensorflow.keras.models.load_model('/home/jmv/data/mlproj1_new/tmp/20200304-232855/00062_0.104636_0.969000_0.155657_0.948171.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tstDataGen = tensorflow.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "tstGenerator = tstDataGen.flow_from_directory(\n",
    "    directory=tstDir,\n",
    "    target_size=(imageHeight,imageWidth),\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False)\n",
    "\n",
    "# Confusion matrix\n",
    "predictions = model.predict_generator(tstGenerator,numpy.math.ceil(tstGenerator.samples/tstGenerator.batch_size))\n",
    "images = tstGenerator.filenames\n",
    "trueClasses = tstGenerator.classes\n",
    "predictedClasses = numpy.argmax(predictions, axis=1)\n",
    "\n",
    "report = sklearn.metrics.confusion_matrix(trueClasses, predictedClasses)\n",
    "\n",
    "print(tstGenerator.class_indices)\n",
    "print(report)\n",
    "\n",
    "# Request from Signify on Feb. 7, 2020\n",
    "# List images which have a different predicted class vs. true class\n",
    "for image, trueClass, predictedClass in zip(images,trueClasses,predictedClasses):\n",
    "    if trueClass!=predictedClass:\n",
    "        print(\"Image: %s, True Class: %d, Predicted Class: %d\" % (image, trueClass, predictedClass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remDataGen = tensorflow.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "remGenerator = remDataGen.flow_from_directory(\n",
    "    directory=remDir,\n",
    "    target_size=(imageHeight,imageWidth),\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False)\n",
    "\n",
    "# Confusion matrix\n",
    "predictions = model.predict_generator(remGenerator,numpy.math.ceil(remGenerator.samples/remGenerator.batch_size))\n",
    "images = remGenerator.filenames\n",
    "trueClasses = remGenerator.classes\n",
    "predictedClasses = numpy.argmax(predictions, axis=1)\n",
    "\n",
    "report = sklearn.metrics.confusion_matrix(trueClasses, predictedClasses)\n",
    "\n",
    "print(remGenerator.class_indices)\n",
    "print(report)\n",
    "\n",
    "for image, trueClass, predictedClass in zip(images,trueClasses,predictedClasses):\n",
    "    if trueClass!=predictedClass:\n",
    "        print(\"Image: %s, True Class: %d, Predicted Class: %d\" % (image, trueClass, predictedClass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# From book \"Deep Learning w/ Python\" by FranÃ§ois Chollet\n",
    "# From https://stackoverflow.com/questions/58322147/how-to-generate-cnn-heatmaps-using-built-in-keras-in-tf2-0-tf-keras\n",
    "import matplotlib.pyplot\n",
    "import cv2\n",
    "import PIL\n",
    "\n",
    "def plot_activation(imagePath):\n",
    "    # Loads an image into PIL format\n",
    "    myImage = tensorflow.keras.preprocessing.image.load_img(imagePath,target_size=(imageHeight,imageWidth))\n",
    "    # Converts the PIL image into a Numpy array\n",
    "    myImageAsArray = tensorflow.keras.preprocessing.image.img_to_array(myImage)\n",
    "    # Creates a list containing a single image [myImageAsArray]\n",
    "    myImageAsArray = numpy.expand_dims(myImageAsArray,axis=0)\n",
    "    # Scales the image in the same way as what we did before the training\n",
    "    myImageAsArray /= 255.0\n",
    "    # Gets the result of the model\n",
    "    myPrediction = model.predict(myImageAsArray)\n",
    "    myPredictedClass = numpy.argmax(myPrediction, axis=1)\n",
    "    #print(f\"DBG> Predicted class: {myPredictedClass[0]}\")\n",
    "    #\n",
    "    convLayer = model.get_layer(\"block5_conv3\")\n",
    "    #print(\"DBG> convLayer is\",convLayer)\n",
    "    modelOutput = model.output[:,myPredictedClass[0]]\n",
    "    # Was forced to add tensorflow.cast(...,'float32') because otherwise the tensor is missing\n",
    "    # dtype set to float32. Bug with TF1.14?\n",
    "    #grads = tensorflow.cast(tensorflow.keras.backend.gradients(modelOutput,convLayer.output),'float32')\n",
    "    grads = tensorflow.keras.backend.gradients(modelOutput,convLayer.output)[0]\n",
    "    pooledGrads = tensorflow.keras.backend.mean(grads,axis=(0,1,2))\n",
    "    iterate = tensorflow.keras.backend.function([model.input],[pooledGrads,convLayer.output[0]])\n",
    "    pooledGradsValue, convLayerOutputValue = iterate([myImageAsArray])\n",
    "    numberOfChannelsConvLayer = convLayer.output[0].get_shape()[2]\n",
    "    for i in range(numberOfChannelsConvLayer):\n",
    "        convLayerOutputValue[:,:,i] *= pooledGradsValue[i]\n",
    "    heatMap = numpy.mean(convLayerOutputValue, axis=-1)\n",
    "    heatMap = numpy.maximum(heatMap,0)\n",
    "    heatMap /= numpy.max(heatMap)\n",
    "    matplotlib.pyplot.matshow(heatMap)\n",
    "    #\n",
    "    img = cv2.imread(imagePath)\n",
    "    heatMap = cv2.resize(heatMap,(img.shape[1],img.shape[0]))\n",
    "    heatMap =numpy.uint8(255*heatMap)\n",
    "    heatMap = cv2.applyColorMap(heatMap,cv2.COLORMAP_JET)\n",
    "    superImposedImg = heatMap*0.4+img\n",
    "    cv2.imwrite('/home/jmv/data/mlproj8/myresultingimage.jpg',superImposedImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desiredNumberOfImagesToDisplay = 10\n",
    "dirToDisplayFrom = tstDir\n",
    "print(f\"DBG> Desired number of images: {desiredNumberOfImagesToDisplay}\")\n",
    "print(f\"DBG> Directory to display images from: {dirToDisplayFrom}\")\n",
    "\n",
    "for myClass in sorted(os.listdir(dirToDisplayFrom)):\n",
    "    print(f\"DBG> Class={myClass}\")\n",
    "    listOfImages = [image for image in sorted(os.listdir(os.path.join(tstDir,myClass))) if \"copy\" not in image]\n",
    "    actualNumberOfImagesToDisplay = len(listOfImages)\n",
    "    print(f\"DBG> Actual number of images: {actualNumberOfImagesToDisplay}\")\n",
    "    for image in listOfImages[:min(desiredNumberOfImagesToDisplay,actualNumberOfImagesToDisplay)]:\n",
    "        print(f\"DBG> Image: {image}\")\n",
    "        selectImage = os.path.join(tstDir,myClass,image)\n",
    "        plot_activation(selectImage)\n",
    "        pil_img = PIL.Image.open('/home/jmv/data/mlproj8/myresultingimage.jpg')\n",
    "        myImShow = matplotlib.pyplot.imshow(pil_img)\n",
    "        matplotlib.pyplot.title(selectImage,pad=30)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
