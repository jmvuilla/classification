{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO> TensorFlow version: 1.14.0\n",
      "INFO> Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import datetime\n",
    "import numpy\n",
    "import random\n",
    "import sklearn.metrics\n",
    "import tensorflow\n",
    "\n",
    "print(\"INFO> TensorFlow version: %s\" % tensorflow.__version__)\n",
    "print(\"INFO> Num GPUs Available: \", len(tensorflow.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO> Reading file config.yam from directory: /raid5/disk1/mlproj10/classification\n",
      "INFO> batchSize      : 16\n",
      "INFO> checkDataset   : True\n",
      "INFO> checkpointDir  : /home/jmv/data/mlproj10/tmp/\n",
      "INFO> createDataset  : True\n",
      "INFO> datasetDir     : /home/jmv/data/mlproj10/dataset\n",
      "INFO> goldenDataset  : /home/jmv/data/mlproj10/LeryPosesGolden/dataset\n",
      "INFO> imageHeight    : 360\n",
      "INFO> imageWidth     : 640\n",
      "INFO> learningRate   : 1e-6\n",
      "INFO> logDir         : /home/jmv/data/mlproj10/log/\n",
      "INFO> nEpochs        : 1000\n",
      "INFO> nTrnSamples    : 2000\n",
      "INFO> nTstSamples    : 671\n",
      "INFO> nValSamples    : 671\n",
      "INFO> remDir         : rem\n",
      "INFO> tmpDir         : tmp\n",
      "INFO> trnDir         : trn\n",
      "INFO> tstDir         : tst\n",
      "INFO> valDir         : val\n"
     ]
    }
   ],
   "source": [
    "# Read parameters from local config.yaml file, and update corresponding Python variables\n",
    "currentDir = os.getcwd()\n",
    "print(\"INFO> Reading file config.yam from directory: %s\" % currentDir)\n",
    "yamlFile = open('config.yaml','r')\n",
    "yamlData = yaml.load(yamlFile,Loader=yaml.Loader)\n",
    "\n",
    "for key in sorted(yamlData):\n",
    "    print(\"INFO> %-15s: %s\" % (key,yamlData[key]))\n",
    "\n",
    "batchSize = yamlData['batchSize']\n",
    "checkDataset = yamlData['checkDataset']\n",
    "checkpointDir = yamlData['checkpointDir']\n",
    "createDataset = yamlData['createDataset']\n",
    "datasetDir = yamlData['datasetDir']\n",
    "goldenDataset = yamlData['goldenDataset']\n",
    "imageHeight = yamlData['imageHeight']\n",
    "imageWidth = yamlData['imageWidth']\n",
    "learningRate = float(yamlData['learningRate'])\n",
    "logDir = yamlData['logDir']\n",
    "nEpochs = yamlData['nEpochs']\n",
    "nTrnSamples = yamlData['nTrnSamples']\n",
    "nTstSamples = yamlData['nTstSamples']\n",
    "nValSamples = yamlData['nValSamples']\n",
    "remDir = os.path.join(yamlData['datasetDir'], yamlData['remDir'])\n",
    "tmpDir = os.path.join(yamlData['datasetDir'], yamlData['tmpDir'])\n",
    "trnDir = os.path.join(yamlData['datasetDir'], yamlData['trnDir'])\n",
    "tstDir = os.path.join(yamlData['datasetDir'], yamlData['tstDir'])\n",
    "valDir = os.path.join(yamlData['datasetDir'], yamlData['valDir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder (1st pass): 0windsurf\n",
      "Processing folder (1st pass): 1windsurf\n",
      "Processing folder (2nd pass): 0windsurf\n",
      "Processing folder (2nd pass): 1windsurf\n",
      "INFO> Processing folder: rem\n",
      "INFO>     Number of samples in class 0windsurf: 414\n",
      "INFO>     Number of samples in class 1windsurf: 16\n",
      "INFO> Processing folder: tmp\n",
      "INFO>     Number of samples in class 0windsurf: 3756\n",
      "INFO>     Number of samples in class 1windsurf: 3358\n",
      "INFO> Processing folder: trn\n",
      "INFO>     Number of samples in class 0windsurf: 2000\n",
      "INFO>     Number of samples in class 1windsurf: 2000\n",
      "INFO> Processing folder: tst\n",
      "INFO>     Number of samples in class 0windsurf: 671\n",
      "INFO>     Number of samples in class 1windsurf: 671\n",
      "INFO> Processing folder: val\n",
      "INFO>     Number of samples in class 0windsurf: 671\n",
      "INFO>     Number of samples in class 1windsurf: 671\n"
     ]
    }
   ],
   "source": [
    "# Optionally create dataset from golden data set & check the newly created dataset\n",
    "if createDataset:\n",
    "    # Remove datasetDir folder & sub-folders - and then create it again to start from scratch\n",
    "    shutil.rmtree(datasetDir, ignore_errors=True)\n",
    "    os.mkdir(datasetDir)\n",
    "    \n",
    "    # For each class from goldenDataset:\n",
    "    #  - create a corresponding subfolder in tmpDir\n",
    "    #  - copy all images from the corresponding class in goldenDataset to the corresponding class in tmpDir\n",
    "    listOfSubDirs = [subdir[1] for subdir in os.walk(goldenDataset)][0]\n",
    "    for myClass in listOfSubDirs:\n",
    "        print(f\"INFO> Processing folder (1st pass): {myClass}\")\n",
    "        os.makedirs(os.path.join(tmpDir,myClass))\n",
    "\n",
    "        for myImage in [image[2] for image in os.walk(os.path.join(goldenDataset,myClass))][0]:\n",
    "            shutil.copyfile(os.path.join(goldenDataset,myClass,myImage),os.path.join(tmpDir,myClass,myImage))\n",
    "        os.makedirs(os.path.join(trnDir,myClass))\n",
    "        os.makedirs(os.path.join(valDir,myClass))\n",
    "        os.makedirs(os.path.join(tstDir,myClass))\n",
    "        os.makedirs(os.path.join(remDir,myClass))\n",
    "\n",
    "    # Oversampling section\n",
    "    def overSample(myList,actualLength,desiredLength): \n",
    "        if actualLength==desiredLength:\n",
    "            return myList\n",
    "        else:\n",
    "            newList = numpy.append(myList,numpy.random.choice(myList,desiredLength-actualLength)) \n",
    "            return numpy.random.choice(newList,desiredLength,replace=False)\n",
    "    \n",
    "    def copyImages(tmpDir, subDir, listOfImages, dstDir):\n",
    "        cntDict={}\n",
    "        for image in listOfImages:\n",
    "            cntDict[image] = cntDict.get(image,0)+1\n",
    "            if cntDict[image]==1:\n",
    "                dstImage = image\n",
    "            else:\n",
    "                fileName, fileExtension = os.path.splitext(image)\n",
    "                dstImage = fileName+\"_copy_\"+str(cntDict[image])+fileExtension\n",
    "            shutil.copyfile(os.path.join(tmpDir,subDir,image),os.path.join(dstDir,subDir,dstImage))\n",
    "        \n",
    "    random.seed(42)\n",
    "    \n",
    "    listOfSubDir = [subdir[1] for subdir in os.walk(tmpDir)][0]\n",
    "    for subDir in listOfSubDir:\n",
    "        print(\"INFO> Processing folder (2nd pass): %s\" % subDir)\n",
    "    \n",
    "        initialList=os.listdir(os.path.join(tmpDir,subDir))\n",
    "        nInitialList = len(initialList)\n",
    "        randomInitialList = random.sample(initialList,k=nInitialList)\n",
    "        \n",
    "        # Split randomized list of images according to the training, validation & test ratio\n",
    "        nTotalSamples = nTrnSamples + nValSamples + nTstSamples\n",
    "        trnN = min(nTrnSamples,int(nInitialList*nTrnSamples/nTotalSamples))\n",
    "        valN = min(nTrnSamples+nValSamples,int(nInitialList*(nTrnSamples+nValSamples)/nTotalSamples))\n",
    "        tstN = min(nTotalSamples,nInitialList)\n",
    "        trn, val, tst, rem = numpy.split(randomInitialList,[trnN, valN, tstN])\n",
    "    \n",
    "        # Oversampling scheme\n",
    "        trnLen = trnN\n",
    "        valLen = valN-trnN\n",
    "        tstLen = tstN-valN\n",
    "        fullTrn = overSample(trn,trnLen,nTrnSamples)\n",
    "        fullVal = overSample(val,valLen,nValSamples)\n",
    "        fullTst = overSample(tst,tstLen,nTstSamples)\n",
    "        fullRem = rem # No oversampling for rem\n",
    "    \n",
    "        # Copy images in folders\n",
    "        copyImages(tmpDir, subDir, fullTrn, trnDir)\n",
    "        copyImages(tmpDir, subDir, fullVal, valDir)\n",
    "        copyImages(tmpDir, subDir, fullTst, tstDir)        \n",
    "        copyImages(tmpDir, subDir, fullRem, remDir)   \n",
    "    \n",
    "if checkDataset:\n",
    "    for subDir in sorted(os.listdir(datasetDir)):\n",
    "        print(f\"INFO> Processing folder: {subDir}\")\n",
    "        for myClass in sorted(os.listdir(os.path.join(datasetDir, subDir))):\n",
    "            nImages = len(os.listdir(os.path.join(datasetDir, subDir, myClass)))\n",
    "            print(f\"INFO>     Number of samples in class {myClass}: {nImages}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /raid5/disk1/tensorflow1.14_gpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 360, 640, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 358, 638, 64)      1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 358, 638, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 179, 319, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 177, 317, 128)     73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 177, 317, 128)     512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 88, 158, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 86, 156, 192)      221376    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 86, 156, 192)      768       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 43, 78, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 41, 76, 192)       331968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 41, 76, 192)       768       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 20, 38, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 18, 36, 192)       331968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 18, 36, 192)       768       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 9, 18, 192)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 16, 128)        221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 7, 16, 128)        512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               393344    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,579,841\n",
      "Trainable params: 1,577,793\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /raid5/disk1/tensorflow1.14_gpu/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "myModelInput = tensorflow.keras.layers.Input(shape=(imageHeight,imageWidth,3))\n",
    "x = tensorflow.keras.layers.Conv2D(64, (3,3), activation=\"relu\")(myModelInput)\n",
    "x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "x = tensorflow.keras.layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2D(128, (3,3), activation=\"relu\")(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "x = tensorflow.keras.layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2D(192, (3,3), activation=\"relu\")(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "x = tensorflow.keras.layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2D(192, (3,3), activation=\"relu\")(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "x = tensorflow.keras.layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2D(192, (3,3), activation=\"relu\")(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "x = tensorflow.keras.layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2D(128, (3,3), activation=\"relu\")(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "x = tensorflow.keras.layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Flatten()(x)\n",
    "x = tensorflow.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Dropout(0.25)(x)\n",
    "myModelOutput = tensorflow.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = tensorflow.keras.models.Model(inputs=myModelInput, outputs=myModelOutput)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "tensorflow.keras.optimizers.RMSprop(lr=learningRate)\n",
    " \n",
    "model.compile(loss=tensorflow.keras.losses.BinaryCrossentropy(),\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy']) # should be accuracy in TF2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n",
      "Found 1342 images belonging to 2 classes.\n",
      "Epoch 1/1000\n",
      "125/125 [==============================] - 142s 1s/step - loss: 0.7502 - acc: 0.6515 - val_loss: 3.3281 - val_acc: 0.4954\n",
      "Epoch 2/1000\n",
      "125/125 [==============================] - 131s 1s/step - loss: 0.5605 - acc: 0.7440 - val_loss: 5.2757 - val_acc: 0.4954\n",
      "Epoch 3/1000\n",
      "125/125 [==============================] - 133s 1s/step - loss: 0.5586 - acc: 0.7290 - val_loss: 3.5469 - val_acc: 0.5381\n",
      "Epoch 4/1000\n",
      "125/125 [==============================] - 133s 1s/step - loss: 0.5288 - acc: 0.7410 - val_loss: 0.9153 - val_acc: 0.5213\n",
      "Epoch 5/1000\n",
      "125/125 [==============================] - 131s 1s/step - loss: 0.5029 - acc: 0.7670 - val_loss: 2.1069 - val_acc: 0.4954\n",
      "Epoch 6/1000\n",
      "125/125 [==============================] - 131s 1s/step - loss: 0.4724 - acc: 0.7820 - val_loss: 2.3738 - val_acc: 0.5137\n",
      "Epoch 7/1000\n",
      "125/125 [==============================] - 133s 1s/step - loss: 0.4567 - acc: 0.7910 - val_loss: 2.6968 - val_acc: 0.5854\n",
      "Epoch 8/1000\n",
      "125/125 [==============================] - 131s 1s/step - loss: 0.4650 - acc: 0.7970 - val_loss: 1.2718 - val_acc: 0.6631\n",
      "Epoch 9/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.4457 - acc: 0.7840 - val_loss: 0.7548 - val_acc: 0.7652\n",
      "Epoch 10/1000\n",
      "125/125 [==============================] - 131s 1s/step - loss: 0.4162 - acc: 0.8125 - val_loss: 0.4054 - val_acc: 0.8186\n",
      "Epoch 11/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.4205 - acc: 0.8115 - val_loss: 2.2441 - val_acc: 0.4970\n",
      "Epoch 12/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.4279 - acc: 0.8125 - val_loss: 0.5355 - val_acc: 0.7454\n",
      "Epoch 13/1000\n",
      "125/125 [==============================] - 131s 1s/step - loss: 0.4038 - acc: 0.8260 - val_loss: 0.4274 - val_acc: 0.8095\n",
      "Epoch 14/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.3867 - acc: 0.8340 - val_loss: 0.9779 - val_acc: 0.6387\n",
      "Epoch 15/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.3891 - acc: 0.8325 - val_loss: 0.4675 - val_acc: 0.7881\n",
      "Epoch 16/1000\n",
      "125/125 [==============================] - 131s 1s/step - loss: 0.3943 - acc: 0.8190 - val_loss: 0.4055 - val_acc: 0.8003\n",
      "Epoch 17/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.3544 - acc: 0.8455 - val_loss: 0.6937 - val_acc: 0.6601\n",
      "Epoch 18/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.3842 - acc: 0.8345 - val_loss: 0.4241 - val_acc: 0.7896\n",
      "Epoch 19/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.3562 - acc: 0.8485 - val_loss: 0.4006 - val_acc: 0.8262\n",
      "Epoch 20/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.3354 - acc: 0.8610 - val_loss: 0.4512 - val_acc: 0.7683\n",
      "Epoch 21/1000\n",
      "125/125 [==============================] - 134s 1s/step - loss: 0.3303 - acc: 0.8665 - val_loss: 1.3312 - val_acc: 0.5701\n",
      "Epoch 22/1000\n",
      "125/125 [==============================] - 133s 1s/step - loss: 0.3224 - acc: 0.8585 - val_loss: 1.1769 - val_acc: 0.5290\n",
      "Epoch 23/1000\n",
      "125/125 [==============================] - 133s 1s/step - loss: 0.2840 - acc: 0.8875 - val_loss: 0.4339 - val_acc: 0.8369\n",
      "Epoch 24/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.2865 - acc: 0.8850 - val_loss: 0.3622 - val_acc: 0.8521\n",
      "Epoch 25/1000\n",
      "125/125 [==============================] - 131s 1s/step - loss: 0.2471 - acc: 0.9000 - val_loss: 2.0643 - val_acc: 0.5716\n",
      "Epoch 26/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.2823 - acc: 0.8870 - val_loss: 1.0076 - val_acc: 0.6113\n",
      "Epoch 27/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.2419 - acc: 0.9050 - val_loss: 0.7630 - val_acc: 0.7058\n",
      "Epoch 28/1000\n",
      "125/125 [==============================] - 130s 1s/step - loss: 0.2128 - acc: 0.9170 - val_loss: 0.4385 - val_acc: 0.7835\n",
      "Epoch 29/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.2227 - acc: 0.9160 - val_loss: 0.3082 - val_acc: 0.8704\n",
      "Epoch 30/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.2214 - acc: 0.9090 - val_loss: 0.5564 - val_acc: 0.8506\n",
      "Epoch 31/1000\n",
      "125/125 [==============================] - 133s 1s/step - loss: 0.2005 - acc: 0.9245 - val_loss: 0.9149 - val_acc: 0.7149\n",
      "Epoch 32/1000\n",
      "125/125 [==============================] - 133s 1s/step - loss: 0.1926 - acc: 0.9285 - val_loss: 0.6308 - val_acc: 0.7180\n",
      "Epoch 33/1000\n",
      "125/125 [==============================] - 131s 1s/step - loss: 0.1984 - acc: 0.9275 - val_loss: 2.4334 - val_acc: 0.5701\n",
      "Epoch 34/1000\n",
      "125/125 [==============================] - 133s 1s/step - loss: 0.1913 - acc: 0.9325 - val_loss: 0.1656 - val_acc: 0.9436\n",
      "Epoch 35/1000\n",
      "125/125 [==============================] - 133s 1s/step - loss: 0.1901 - acc: 0.9335 - val_loss: 0.2033 - val_acc: 0.9223\n",
      "Epoch 36/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1870 - acc: 0.9295 - val_loss: 0.1902 - val_acc: 0.9360\n",
      "Epoch 37/1000\n",
      "125/125 [==============================] - 131s 1s/step - loss: 0.1612 - acc: 0.9410 - val_loss: 0.2798 - val_acc: 0.9024\n",
      "Epoch 38/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1901 - acc: 0.9285 - val_loss: 0.4441 - val_acc: 0.8140\n",
      "Epoch 39/1000\n",
      "125/125 [==============================] - 133s 1s/step - loss: 0.1643 - acc: 0.9400 - val_loss: 1.4830 - val_acc: 0.5762\n",
      "Epoch 40/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1727 - acc: 0.9400 - val_loss: 0.3227 - val_acc: 0.8826\n",
      "Epoch 41/1000\n",
      "125/125 [==============================] - 133s 1s/step - loss: 0.1660 - acc: 0.9385 - val_loss: 0.2252 - val_acc: 0.9192\n",
      "Epoch 42/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1498 - acc: 0.9455 - val_loss: 0.2110 - val_acc: 0.9253\n",
      "Epoch 43/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1594 - acc: 0.9430 - val_loss: 0.6809 - val_acc: 0.7622\n",
      "Epoch 44/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1816 - acc: 0.9380 - val_loss: 0.2456 - val_acc: 0.9055\n",
      "Epoch 45/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1568 - acc: 0.9385 - val_loss: 1.2113 - val_acc: 0.6037\n",
      "Epoch 46/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1814 - acc: 0.9310 - val_loss: 0.2103 - val_acc: 0.9314\n",
      "Epoch 47/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1525 - acc: 0.9500 - val_loss: 0.2226 - val_acc: 0.9360\n",
      "Epoch 48/1000\n",
      "125/125 [==============================] - 131s 1s/step - loss: 0.1474 - acc: 0.9465 - val_loss: 0.6629 - val_acc: 0.7043\n",
      "Epoch 49/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1415 - acc: 0.9525 - val_loss: 0.3034 - val_acc: 0.8750\n",
      "Epoch 50/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1654 - acc: 0.9440 - val_loss: 0.4116 - val_acc: 0.8537\n",
      "Epoch 51/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1167 - acc: 0.9560 - val_loss: 4.2241 - val_acc: 0.5213\n",
      "Epoch 52/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1399 - acc: 0.9475 - val_loss: 0.6038 - val_acc: 0.7332\n",
      "Epoch 53/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1436 - acc: 0.9515 - val_loss: 0.6489 - val_acc: 0.7698\n",
      "Epoch 54/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1471 - acc: 0.9510 - val_loss: 0.4460 - val_acc: 0.8247\n",
      "Epoch 55/1000\n",
      "125/125 [==============================] - 133s 1s/step - loss: 0.1573 - acc: 0.9415 - val_loss: 0.6501 - val_acc: 0.7454\n",
      "Epoch 56/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1336 - acc: 0.9565 - val_loss: 0.1860 - val_acc: 0.9390\n",
      "Epoch 57/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1446 - acc: 0.9455 - val_loss: 0.1916 - val_acc: 0.9345\n",
      "Epoch 58/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1199 - acc: 0.9615 - val_loss: 0.6763 - val_acc: 0.7378\n",
      "Epoch 59/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1535 - acc: 0.9470 - val_loss: 0.7555 - val_acc: 0.7241\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 131s 1s/step - loss: 0.1308 - acc: 0.9535 - val_loss: 0.4525 - val_acc: 0.8171\n",
      "Epoch 61/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1322 - acc: 0.9575 - val_loss: 0.7266 - val_acc: 0.7058\n",
      "Epoch 62/1000\n",
      "125/125 [==============================] - 131s 1s/step - loss: 0.1095 - acc: 0.9620 - val_loss: 0.5126 - val_acc: 0.8125\n",
      "Epoch 63/1000\n",
      "125/125 [==============================] - 131s 1s/step - loss: 0.1389 - acc: 0.9510 - val_loss: 0.2355 - val_acc: 0.9314\n",
      "Epoch 64/1000\n",
      "125/125 [==============================] - 131s 1s/step - loss: 0.1412 - acc: 0.9490 - val_loss: 0.5278 - val_acc: 0.8491\n",
      "Epoch 65/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1165 - acc: 0.9640 - val_loss: 0.2438 - val_acc: 0.9177\n",
      "Epoch 66/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1241 - acc: 0.9555 - val_loss: 0.2773 - val_acc: 0.8994\n",
      "Epoch 67/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1106 - acc: 0.9580 - val_loss: 0.1759 - val_acc: 0.9390\n",
      "Epoch 68/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1388 - acc: 0.9490 - val_loss: 0.3759 - val_acc: 0.8979\n",
      "Epoch 69/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1257 - acc: 0.9550 - val_loss: 0.2732 - val_acc: 0.9299\n",
      "Epoch 70/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1255 - acc: 0.9565 - val_loss: 0.2158 - val_acc: 0.9238\n",
      "Epoch 71/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1232 - acc: 0.9530 - val_loss: 0.3969 - val_acc: 0.8826\n",
      "Epoch 72/1000\n",
      "125/125 [==============================] - 133s 1s/step - loss: 0.1307 - acc: 0.9545 - val_loss: 4.0949 - val_acc: 0.5122\n",
      "Epoch 73/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.0918 - acc: 0.9660 - val_loss: 0.1483 - val_acc: 0.9497\n",
      "Epoch 74/1000\n",
      "125/125 [==============================] - 131s 1s/step - loss: 0.1191 - acc: 0.9620 - val_loss: 0.2559 - val_acc: 0.9177\n",
      "Epoch 75/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1111 - acc: 0.9590 - val_loss: 1.1130 - val_acc: 0.7043\n",
      "Epoch 76/1000\n",
      "125/125 [==============================] - 131s 1s/step - loss: 0.1047 - acc: 0.9660 - val_loss: 0.7781 - val_acc: 0.6860\n",
      "Epoch 77/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.0926 - acc: 0.9700 - val_loss: 0.2902 - val_acc: 0.9238\n",
      "Epoch 78/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1309 - acc: 0.9545 - val_loss: 0.2846 - val_acc: 0.9085\n",
      "Epoch 79/1000\n",
      "125/125 [==============================] - 131s 1s/step - loss: 0.1079 - acc: 0.9625 - val_loss: 0.2045 - val_acc: 0.9299\n",
      "Epoch 80/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1076 - acc: 0.9575 - val_loss: 0.2348 - val_acc: 0.9070\n",
      "Epoch 81/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1069 - acc: 0.9620 - val_loss: 0.1782 - val_acc: 0.9451\n",
      "Epoch 82/1000\n",
      "125/125 [==============================] - 131s 1s/step - loss: 0.1214 - acc: 0.9625 - val_loss: 0.2090 - val_acc: 0.9421\n",
      "Epoch 83/1000\n",
      "125/125 [==============================] - 133s 1s/step - loss: 0.1089 - acc: 0.9665 - val_loss: 0.3405 - val_acc: 0.8613\n",
      "Epoch 84/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1127 - acc: 0.9645 - val_loss: 0.4170 - val_acc: 0.8476\n",
      "Epoch 85/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.0920 - acc: 0.9700 - val_loss: 0.1961 - val_acc: 0.9390\n",
      "Epoch 86/1000\n",
      "125/125 [==============================] - 131s 1s/step - loss: 0.1175 - acc: 0.9600 - val_loss: 0.2728 - val_acc: 0.9375\n",
      "Epoch 87/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1149 - acc: 0.9610 - val_loss: 0.1557 - val_acc: 0.9466\n",
      "Epoch 88/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1014 - acc: 0.9635 - val_loss: 0.1678 - val_acc: 0.9482\n",
      "Epoch 89/1000\n",
      "125/125 [==============================] - 132s 1s/step - loss: 0.1061 - acc: 0.9630 - val_loss: 0.3448 - val_acc: 0.9146\n",
      "Epoch 90/1000\n",
      " 86/125 [===================>..........] - ETA: 35s - loss: 0.1273 - acc: 0.9615"
     ]
    }
   ],
   "source": [
    "trnDataGen = tensorflow.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "valDataGen = tensorflow.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "trnGenerator = trnDataGen.flow_from_directory(\n",
    "    trnDir,\n",
    "    target_size=(imageHeight,imageWidth),\n",
    "    batch_size=batchSize,\n",
    "    class_mode='binary')\n",
    "\n",
    "valGenerator = valDataGen.flow_from_directory(\n",
    "    valDir,\n",
    "    target_size=(imageHeight,imageWidth),\n",
    "    batch_size=batchSize,\n",
    "    class_mode='binary')\n",
    "\n",
    "timeNow = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "fullCheckpointDir = os.path.join(checkpointDir,timeNow)\n",
    "os.mkdir(fullCheckpointDir)\n",
    "                                           \n",
    "# need to replace acc by accuracy below when moving to TF2.0    \n",
    "filePath = os.path.join(fullCheckpointDir,\"{epoch:05d}_{loss:.6f}_{acc:.6f}_{val_loss:.6f}_{val_acc:.6f}.h5\")\n",
    "checkpoint = tensorflow.keras.callbacks.ModelCheckpoint(filePath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
    "\n",
    "# profile_batch=0 required to solve a bug w/ Tensorboard according to     \n",
    "#   https://github.com/tensorflow/tensorboard/issues/2412    \n",
    "fullLogDir = os.path.join(logDir, timeNow)\n",
    "tensorboardCallback = tensorflow.keras.callbacks.TensorBoard(log_dir=fullLogDir,profile_batch=0)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    trnGenerator,\n",
    "    steps_per_epoch=nTrnSamples // batchSize,\n",
    "    epochs=nEpochs,\n",
    "    validation_data=valGenerator,\n",
    "    validation_steps=nValSamples // batchSize,\n",
    "    callbacks=[tensorboardCallback,checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
