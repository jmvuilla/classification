{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO> TensorFlow version: 1.14.0\n",
      "INFO> Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import datetime\n",
    "import numpy\n",
    "import random\n",
    "import sklearn.metrics\n",
    "import tensorflow\n",
    "\n",
    "print(\"INFO> TensorFlow version: %s\" % tensorflow.__version__)\n",
    "print(\"INFO> Num GPUs Available: \", len(tensorflow.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO> Reading file config.yam from directory: /raid5/disk1/mlproj10/classification\n",
      "INFO> batchSize      : 16\n",
      "INFO> checkDataset   : True\n",
      "INFO> checkpointDir  : /home/jmv/data/mlproj10/tmp/\n",
      "INFO> createDataset  : True\n",
      "INFO> datasetDir     : /home/jmv/data/mlproj10/dataset\n",
      "INFO> goldenDataset  : /home/jmv/data/mlproj10/LeryPosesGolden/dataset\n",
      "INFO> imageHeight    : 720\n",
      "INFO> imageWidth     : 1280\n",
      "INFO> learningRate   : 1e-6\n",
      "INFO> logDir         : /home/jmv/data/mlproj10/log/\n",
      "INFO> nEpochs        : 1000\n",
      "INFO> nTrnSamples    : 2000\n",
      "INFO> nTstSamples    : 671\n",
      "INFO> nValSamples    : 671\n",
      "INFO> remDir         : rem\n",
      "INFO> tmpDir         : tmp\n",
      "INFO> trnDir         : trn\n",
      "INFO> tstDir         : tst\n",
      "INFO> valDir         : val\n"
     ]
    }
   ],
   "source": [
    "# Read parameters from local config.yaml file, and update corresponding Python variables\n",
    "currentDir = os.getcwd()\n",
    "print(\"INFO> Reading file config.yam from directory: %s\" % currentDir)\n",
    "yamlFile = open('config.yaml','r')\n",
    "yamlData = yaml.load(yamlFile,Loader=yaml.Loader)\n",
    "\n",
    "for key in sorted(yamlData):\n",
    "    print(\"INFO> %-15s: %s\" % (key,yamlData[key]))\n",
    "    \n",
    "# To be done - let's remove the code below - it is un-necessary\n",
    "# Idea is to replace for example batchSize by yamlData['batchSize'] wherever batchSize is currently used\n",
    "batchSize = yamlData['batchSize']\n",
    "checkDataset = yamlData['checkDataset']\n",
    "checkpointDir = yamlData['checkpointDir']\n",
    "createDataset = yamlData['createDataset']\n",
    "datasetDir = yamlData['datasetDir']\n",
    "goldenDataset = yamlData['goldenDataset']\n",
    "imageHeight = yamlData['imageHeight']\n",
    "imageWidth = yamlData['imageWidth']\n",
    "learningRate = float(yamlData['learningRate'])\n",
    "logDir = yamlData['logDir']\n",
    "nEpochs = yamlData['nEpochs']\n",
    "nTrnSamples = yamlData['nTrnSamples']\n",
    "nTstSamples = yamlData['nTstSamples']\n",
    "nValSamples = yamlData['nValSamples']\n",
    "remDir = os.path.join(yamlData['datasetDir'], yamlData['remDir'])\n",
    "tmpDir = os.path.join(yamlData['datasetDir'], yamlData['tmpDir'])\n",
    "trnDir = os.path.join(yamlData['datasetDir'], yamlData['trnDir'])\n",
    "tstDir = os.path.join(yamlData['datasetDir'], yamlData['tstDir'])\n",
    "valDir = os.path.join(yamlData['datasetDir'], yamlData['valDir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO> Processing folder (1st pass): 0windsurf\n",
      "INFO> Processing folder (1st pass): 1windsurf\n",
      "INFO> Processing folder (2nd pass): 0windsurf\n",
      "INFO> Processing folder (2nd pass): 1windsurf\n",
      "INFO> Processing folder: rem\n",
      "INFO>     Number of samples in class 0windsurf: 414\n",
      "INFO>     Number of samples in class 1windsurf: 16\n",
      "INFO> Processing folder: tmp\n",
      "INFO>     Number of samples in class 0windsurf: 3756\n",
      "INFO>     Number of samples in class 1windsurf: 3358\n",
      "INFO> Processing folder: trn\n",
      "INFO>     Number of samples in class 0windsurf: 2000\n",
      "INFO>     Number of samples in class 1windsurf: 2000\n",
      "INFO> Processing folder: tst\n",
      "INFO>     Number of samples in class 0windsurf: 671\n",
      "INFO>     Number of samples in class 1windsurf: 671\n",
      "INFO> Processing folder: val\n",
      "INFO>     Number of samples in class 0windsurf: 671\n",
      "INFO>     Number of samples in class 1windsurf: 671\n"
     ]
    }
   ],
   "source": [
    "# Optionally create dataset from golden data set & check the newly created dataset\n",
    "if createDataset:\n",
    "    # Remove datasetDir folder & sub-folders - and then create it again to start from scratch\n",
    "    shutil.rmtree(datasetDir, ignore_errors=True)\n",
    "    os.mkdir(datasetDir)\n",
    "    \n",
    "    # For each class from goldenDataset:\n",
    "    #  - create a corresponding subfolder in tmpDir\n",
    "    #  - copy all images from the corresponding class in goldenDataset to the corresponding class in tmpDir\n",
    "    listOfSubDirs = [subdir[1] for subdir in os.walk(goldenDataset)][0]\n",
    "    for myClass in listOfSubDirs:\n",
    "        print(f\"INFO> Processing folder (1st pass): {myClass}\")\n",
    "        os.makedirs(os.path.join(tmpDir,myClass))\n",
    "\n",
    "        for myImage in [image[2] for image in os.walk(os.path.join(goldenDataset,myClass))][0]:\n",
    "            shutil.copyfile(os.path.join(goldenDataset,myClass,myImage),os.path.join(tmpDir,myClass,myImage))\n",
    "        os.makedirs(os.path.join(trnDir,myClass))\n",
    "        os.makedirs(os.path.join(valDir,myClass))\n",
    "        os.makedirs(os.path.join(tstDir,myClass))\n",
    "        os.makedirs(os.path.join(remDir,myClass))\n",
    "\n",
    "    # Oversampling section\n",
    "    def overSample(myList,actualLength,desiredLength): \n",
    "        if actualLength==desiredLength:\n",
    "            return myList\n",
    "        else:\n",
    "            newList = numpy.append(myList,numpy.random.choice(myList,desiredLength-actualLength)) \n",
    "            return numpy.random.choice(newList,desiredLength,replace=False)\n",
    "    \n",
    "    def copyImages(tmpDir, subDir, listOfImages, dstDir):\n",
    "        cntDict={}\n",
    "        for image in listOfImages:\n",
    "            cntDict[image] = cntDict.get(image,0)+1\n",
    "            if cntDict[image]==1:\n",
    "                dstImage = image\n",
    "            else:\n",
    "                fileName, fileExtension = os.path.splitext(image)\n",
    "                dstImage = fileName+\"_copy_\"+str(cntDict[image])+fileExtension\n",
    "            shutil.copyfile(os.path.join(tmpDir,subDir,image),os.path.join(dstDir,subDir,dstImage))\n",
    "        \n",
    "    random.seed(42)\n",
    "    \n",
    "    listOfSubDir = [subdir[1] for subdir in os.walk(tmpDir)][0]\n",
    "    for subDir in listOfSubDir:\n",
    "        print(\"INFO> Processing folder (2nd pass): %s\" % subDir)\n",
    "    \n",
    "        initialList=os.listdir(os.path.join(tmpDir,subDir))\n",
    "        nInitialList = len(initialList)\n",
    "        randomInitialList = random.sample(initialList,k=nInitialList)\n",
    "        \n",
    "        # Split randomized list of images according to the training, validation & test ratio\n",
    "        nTotalSamples = nTrnSamples + nValSamples + nTstSamples\n",
    "        trnN = min(nTrnSamples,int(nInitialList*nTrnSamples/nTotalSamples))\n",
    "        valN = min(nTrnSamples+nValSamples,int(nInitialList*(nTrnSamples+nValSamples)/nTotalSamples))\n",
    "        tstN = min(nTotalSamples,nInitialList)\n",
    "        trn, val, tst, rem = numpy.split(randomInitialList,[trnN, valN, tstN])\n",
    "    \n",
    "        # Oversampling scheme\n",
    "        trnLen = trnN\n",
    "        valLen = valN-trnN\n",
    "        tstLen = tstN-valN\n",
    "        fullTrn = overSample(trn,trnLen,nTrnSamples)\n",
    "        fullVal = overSample(val,valLen,nValSamples)\n",
    "        fullTst = overSample(tst,tstLen,nTstSamples)\n",
    "        fullRem = rem # No oversampling for rem\n",
    "    \n",
    "        # Copy images in folders\n",
    "        copyImages(tmpDir, subDir, fullTrn, trnDir)\n",
    "        copyImages(tmpDir, subDir, fullVal, valDir)\n",
    "        copyImages(tmpDir, subDir, fullTst, tstDir)        \n",
    "        copyImages(tmpDir, subDir, fullRem, remDir)   \n",
    "    \n",
    "if checkDataset:\n",
    "    for subDir in sorted(os.listdir(datasetDir)):\n",
    "        print(f\"INFO> Processing folder: {subDir}\")\n",
    "        for myClass in sorted(os.listdir(os.path.join(datasetDir, subDir))):\n",
    "            nImages = len(os.listdir(os.path.join(datasetDir, subDir, myClass)))\n",
    "            print(f\"INFO>     Number of samples in class {myClass}: {nImages}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 720, 1280, 3)]    0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 718, 1278, 64)     1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 718, 1278, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 359, 639, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 357, 637, 128)     73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 357, 637, 128)     512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 178, 318, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 176, 316, 192)     221376    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 176, 316, 192)     768       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 88, 158, 192)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 86, 156, 192)      331968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 86, 156, 192)      768       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 43, 78, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 41, 76, 192)       331968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 41, 76, 192)       768       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 20, 38, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 18, 36, 128)       221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 18, 36, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 9, 18, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 20736)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               2654336   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,840,833\n",
      "Trainable params: 3,838,785\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "myModelInput = tensorflow.keras.layers.Input(shape=(imageHeight,imageWidth,3))\n",
    "x = tensorflow.keras.layers.Conv2D(64, (3,3), activation=\"relu\")(myModelInput)\n",
    "x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "x = tensorflow.keras.layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2D(128, (3,3), activation=\"relu\")(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "x = tensorflow.keras.layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2D(192, (3,3), activation=\"relu\")(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "x = tensorflow.keras.layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2D(192, (3,3), activation=\"relu\")(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "x = tensorflow.keras.layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2D(192, (3,3), activation=\"relu\")(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "x = tensorflow.keras.layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Conv2D(128, (3,3), activation=\"relu\")(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "x = tensorflow.keras.layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Flatten()(x)\n",
    "x = tensorflow.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tensorflow.keras.layers.Dropout(0.5)(x)\n",
    "myModelOutput = tensorflow.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = tensorflow.keras.models.Model(inputs=myModelInput, outputs=myModelOutput)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "tensorflow.keras.optimizers.RMSprop(lr=learningRate)\n",
    " \n",
    "model.compile(loss=tensorflow.keras.losses.BinaryCrossentropy(),\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy']) # should be accuracy in TF2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n",
      "Found 1342 images belonging to 2 classes.\n",
      "Epoch 1/1000\n",
      " 71/125 [================>.............] - ETA: 21:08 - loss: 0.9204 - acc: 0.6118"
     ]
    }
   ],
   "source": [
    "trnDataGen = tensorflow.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "valDataGen = tensorflow.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "trnGenerator = trnDataGen.flow_from_directory(\n",
    "    trnDir,\n",
    "    target_size=(imageHeight,imageWidth),\n",
    "    batch_size=batchSize,\n",
    "    class_mode='binary')\n",
    "\n",
    "valGenerator = valDataGen.flow_from_directory(\n",
    "    valDir,\n",
    "    target_size=(imageHeight,imageWidth),\n",
    "    batch_size=batchSize,\n",
    "    class_mode='binary')\n",
    "\n",
    "timeNow = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "fullCheckpointDir = os.path.join(checkpointDir,timeNow)\n",
    "os.mkdir(fullCheckpointDir)\n",
    "                                           \n",
    "# need to replace acc by accuracy below when moving to TF2.0    \n",
    "filePath = os.path.join(fullCheckpointDir,\"{epoch:05d}_{loss:.6f}_{acc:.6f}_{val_loss:.6f}_{val_acc:.6f}.h5\")\n",
    "checkpoint = tensorflow.keras.callbacks.ModelCheckpoint(filePath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
    "\n",
    "# profile_batch=0 required to solve a bug w/ Tensorboard according to     \n",
    "#   https://github.com/tensorflow/tensorboard/issues/2412    \n",
    "fullLogDir = os.path.join(logDir, timeNow)\n",
    "tensorboardCallback = tensorflow.keras.callbacks.TensorBoard(log_dir=fullLogDir,profile_batch=0)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    trnGenerator,\n",
    "    steps_per_epoch=nTrnSamples // batchSize,\n",
    "    epochs=nEpochs,\n",
    "    validation_data=valGenerator,\n",
    "    validation_steps=nValSamples // batchSize,\n",
    "    callbacks=[tensorboardCallback,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
