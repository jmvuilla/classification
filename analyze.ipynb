{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO> TensorFlow version: 1.14.0\n",
      "INFO> Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import datetime\n",
    "import numpy\n",
    "import random\n",
    "import sklearn.metrics\n",
    "import tensorflow\n",
    "\n",
    "print(\"INFO> TensorFlow version: %s\" % tensorflow.__version__)\n",
    "print(\"INFO> Num GPUs Available: \", len(tensorflow.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO> Reading file config.yam from directory: /raid5/disk1/mlproj10/classification\n",
      "INFO> batchSize      : 16\n",
      "INFO> checkDataset   : True\n",
      "INFO> checkpointDir  : /home/jmv/data/mlproj10/tmp/\n",
      "INFO> createDataset  : True\n",
      "INFO> datasetDir     : /home/jmv/data/mlproj10/dataset\n",
      "INFO> goldenDataset  : /home/jmv/data/mlproj10/LeryPosesGolden/dataset\n",
      "INFO> imageHeight    : 360\n",
      "INFO> imageWidth     : 640\n",
      "INFO> learningRate   : 1e-6\n",
      "INFO> logDir         : /home/jmv/data/mlproj10/log/\n",
      "INFO> nEpochs        : 1000\n",
      "INFO> nTrnSamples    : 2000\n",
      "INFO> nTstSamples    : 671\n",
      "INFO> nValSamples    : 671\n",
      "INFO> remDir         : rem\n",
      "INFO> tmpDir         : tmp\n",
      "INFO> trnDir         : trn\n",
      "INFO> tstDir         : tst\n",
      "INFO> valDir         : val\n"
     ]
    }
   ],
   "source": [
    "# Read parameters from local config.yaml file, and update corresponding Python variables\n",
    "currentDir = os.getcwd()\n",
    "print(\"INFO> Reading file config.yam from directory: %s\" % currentDir)\n",
    "yamlFile = open('config.yaml','r')\n",
    "yamlData = yaml.load(yamlFile,Loader=yaml.Loader)\n",
    "\n",
    "for key in sorted(yamlData):\n",
    "    print(\"INFO> %-15s: %s\" % (key,yamlData[key]))\n",
    "\n",
    "batchSize = yamlData['batchSize']\n",
    "checkDataset = yamlData['checkDataset']\n",
    "checkpointDir = yamlData['checkpointDir']\n",
    "createDataset = yamlData['createDataset']\n",
    "datasetDir = yamlData['datasetDir']\n",
    "goldenDataset = yamlData['goldenDataset']\n",
    "imageHeight = yamlData['imageHeight']\n",
    "imageWidth = yamlData['imageWidth']\n",
    "learningRate = float(yamlData['learningRate'])\n",
    "logDir = yamlData['logDir']\n",
    "nEpochs = yamlData['nEpochs']\n",
    "nTrnSamples = yamlData['nTrnSamples']\n",
    "nTstSamples = yamlData['nTstSamples']\n",
    "nValSamples = yamlData['nValSamples']\n",
    "remDir = os.path.join(yamlData['datasetDir'], yamlData['remDir'])\n",
    "tmpDir = os.path.join(yamlData['datasetDir'], yamlData['tmpDir'])\n",
    "trnDir = os.path.join(yamlData['datasetDir'], yamlData['trnDir'])\n",
    "tstDir = os.path.join(yamlData['datasetDir'], yamlData['tstDir'])\n",
    "valDir = os.path.join(yamlData['datasetDir'], yamlData['valDir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /raid5/disk1/tensorflow1.14_gpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /raid5/disk1/tensorflow1.14_gpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /raid5/disk1/tensorflow1.14_gpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /raid5/disk1/tensorflow1.14_gpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Look in the tmp directory and select best model candidate based on train/val loss & accuracy\n",
    "# For TF1.14, added compile=False. This is not needed for TF2\n",
    "model = tensorflow.keras.models.load_model('/home/jmv/data/mlproj10/tmp/20200308-150427/00042_0.149766_0.945500_0.211008_0.925305.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstDataGen = tensorflow.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "tstGenerator = tstDataGen.flow_from_directory(\n",
    "    directory=tstDir,\n",
    "    target_size=(imageHeight,imageWidth),\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False)\n",
    "\n",
    "# Confusion matrix\n",
    "predictions = model.predict_generator(tstGenerator,numpy.math.ceil(tstGenerator.samples/tstGenerator.batch_size))\n",
    "images = tstGenerator.filenames\n",
    "trueClasses = tstGenerator.classes\n",
    "predictedClasses = numpy.argmax(predictions, axis=1)\n",
    "\n",
    "report = sklearn.metrics.confusion_matrix(trueClasses, predictedClasses)\n",
    "\n",
    "print(tstGenerator.class_indices)\n",
    "print(report)\n",
    "\n",
    "# List images which have a different predicted class vs. true class\n",
    "for image, trueClass, predictedClass in zip(images,trueClasses,predictedClasses):\n",
    "    if trueClass!=predictedClass:\n",
    "        print(\"Image: %s, True Class: %d, Predicted Class: %d\" % (image, trueClass, predictedClass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remDataGen = tensorflow.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "remGenerator = remDataGen.flow_from_directory(\n",
    "    directory=remDir,\n",
    "    target_size=(imageHeight,imageWidth),\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False)\n",
    "\n",
    "# Confusion matrix\n",
    "predictions = model.predict_generator(remGenerator,numpy.math.ceil(remGenerator.samples/remGenerator.batch_size))\n",
    "images = remGenerator.filenames\n",
    "trueClasses = remGenerator.classes\n",
    "predictedClasses = numpy.argmax(predictions, axis=1)\n",
    "\n",
    "report = sklearn.metrics.confusion_matrix(trueClasses, predictedClasses)\n",
    "\n",
    "print(remGenerator.class_indices)\n",
    "print(report)\n",
    "\n",
    "for image, trueClass, predictedClass in zip(images,trueClasses,predictedClasses):\n",
    "    if trueClass!=predictedClass:\n",
    "        print(\\\"Image: %s, True Class: %d, Predicted Class: %d\\\" % (image, trueClass, predictedClass))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From book \\\"Deep Learning w/ Python\\\" by FranÃ§ois Chollet\n",
    "# From https://stackoverflow.com/questions/58322147/how-to-generate-cnn-heatmaps-using-built-in-keras-in-tf2-0-tf-keras\n",
    "import matplotlib.pyplot\n",
    "import cv2\n",
    "import PIL\n",
    "\n",
    "def plot_activation(imagePath):\n",
    "    # Loads an image into PIL format\n",
    "    myImage = tensorflow.keras.preprocessing.image.load_img(imagePath,target_size=(imageHeight,imageWidth))\n",
    "    # Converts the PIL image into a Numpy array\n",
    "    myImageAsArray = tensorflow.keras.preprocessing.image.img_to_array(myImage)\n",
    "    # Creates a list containing a single image [myImageAsArray]\n",
    "    myImageAsArray = numpy.expand_dims(myImageAsArray,axis=0)\n",
    "    # Scales the image in the same way as what we did before the training\n",
    "    myImageAsArray /= 255.0\n",
    "    # Gets the result of the model    \n",
    "    myPrediction = model.predict(myImageAsArray)    \n",
    "    myPredictedClass = numpy.argmax(myPrediction, axis=1)    \n",
    "    #print(f\\\"DBG> Predicted class: {myPredictedClass[0]}\\\")    \n",
    "    #    \n",
    "    convLayer = model.get_layer(\\\"block5_conv3\\\")    \n",
    "    #print(\\\"DBG> convLayer is\\\",convLayer)    \n",
    "    modelOutput = model.output[:,myPredictedClass[0]]    \n",
    "    # Was forced to add tensorflow.cast(...,'float32') because otherwise the tensor is missing    \n",
    "    # dtype set to float32. Bug with TF1.14?    \n",
    "    #grads = tensorflow.cast(tensorflow.keras.backend.gradients(modelOutput,convLayer.output),'float32')    \n",
    "    grads = tensorflow.keras.backend.gradients(modelOutput,convLayer.output)[0]    \n",
    "    pooledGrads = tensorflow.keras.backend.mean(grads,axis=(0,1,2))    \n",
    "    iterate = tensorflow.keras.backend.function([model.input],[pooledGrads,convLayer.output[0]])    \n",
    "    pooledGradsValue, convLayerOutputValue = iterate([myImageAsArray])    \n",
    "    numberOfChannelsConvLayer = convLayer.output[0].get_shape()[2]    \n",
    "    for i in range(numberOfChannelsConvLayer):    \n",
    "        convLayerOutputValue[:,:,i] *= pooledGradsValue[i]    \n",
    "    heatMap = numpy.mean(convLayerOutputValue, axis=-1)    \n",
    "    heatMap = numpy.maximum(heatMap,0)    \n",
    "    heatMap /= numpy.max(heatMap)    \n",
    "    matplotlib.pyplot.matshow(heatMap)    \n",
    "    #    \n",
    "    img = cv2.imread(imagePath)    \n",
    "    heatMap = cv2.resize(heatMap,(img.shape[1],img.shape[0]))    \n",
    "    heatMap =numpy.uint8(255*heatMap)    \n",
    "    heatMap = cv2.applyColorMap(heatMap,cv2.COLORMAP_JET)    \n",
    "    superImposedImg = heatMap*0.4+img    \n",
    "    cv2.imwrite('/home/jmv/data/mlproj8/myresultingimage.jpg',superImposedImg)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desiredNumberOfImagesToDisplay = 10    \n",
    "dirToDisplayFrom = tstDir    \n",
    "print(f\\\"DBG> Desired number of images: {desiredNumberOfImagesToDisplay}\\\")    \n",
    "print(f\\\"DBG> Directory to display images from: {dirToDisplayFrom}\\\")    \n",
    "  \n",
    "for myClass in sorted(os.listdir(dirToDisplayFrom)):    \n",
    "    print(f\\\"DBG> Class={myClass}\\\")    \n",
    "    listOfImages = [image for image in sorted(os.listdir(os.path.join(tstDir,myClass))) if \\\"copy\\\" not in image]    \n",
    "    actualNumberOfImagesToDisplay = len(listOfImages)    \n",
    "    print(f\\\"DBG> Actual number of images: {actualNumberOfImagesToDisplay}\\\")    \n",
    "    for image in listOfImages[:min(desiredNumberOfImagesToDisplay,actualNumberOfImagesToDisplay)]:    \n",
    "        print(f\\\"DBG> Image: {image}\\\")    \n",
    "        selectImage = os.path.join(tstDir,myClass,image)    \n",
    "        plot_activation(selectImage)    \n",
    "        pil_img = PIL.Image.open('/home/jmv/data/mlproj8/myresultingimage.jpg')    \n",
    "        myImShow = matplotlib.pyplot.imshow(pil_img)    \n",
    "        matplotlib.pyplot.title(selectImage,pad=30)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
