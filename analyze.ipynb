{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO> TensorFlow version : 2.1.0\n",
      "INFO> # of GPUs available: 1\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import datetime\n",
    "import numpy\n",
    "import random\n",
    "import sklearn.metrics\n",
    "import tensorflow\n",
    "import matplotlib.pyplot\n",
    "import tf_explain\n",
    "import PIL\n",
    "\n",
    "print(\"INFO> TensorFlow version : %s\" % tensorflow.__version__)\n",
    "print(\"INFO> # of GPUs available: %d\" % len(tensorflow.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO> Reading file config.yam from directory: /raid5/disk1/mlproj11/classification\n",
      "INFO> batchSize      : 8\n",
      "INFO> checkDataset   : True\n",
      "INFO> checkpointDir  : /home/jmv/data/mlproj11/tmp/\n",
      "INFO> createDataset  : True\n",
      "INFO> datasetDir     : /home/jmv/data/mlproj11/dataset\n",
      "INFO> goldenDataset  : /home/jmv/data/mlproj11/SignifyGolden20191212/dataset\n",
      "INFO> imageHeight    : 500\n",
      "INFO> imageWidth     : 768\n",
      "INFO> learningRate   : 1e-3\n",
      "INFO> logDir         : /home/jmv/data/mlproj11/log/\n",
      "INFO> nEpochs        : 1000\n",
      "INFO> trnDir         : /home/jmv/data/mlproj11/dataset/trn\n",
      "INFO> tstDir         : /home/jmv/data/mlproj11/dataset/tst\n",
      "INFO> valDir         : /home/jmv/data/mlproj11/dataset/val\n"
     ]
    }
   ],
   "source": [
    "# Read parameters from local config.yaml file, and update corresponding Python variables\n",
    "currentDir = os.getcwd()\n",
    "print(\"INFO> Reading file config.yam from directory: %s\" % currentDir)\n",
    "yamlFile = open('config.yaml','r')\n",
    "yamlData = yaml.load(yamlFile,Loader=yaml.Loader)\n",
    "\n",
    "for key in sorted(yamlData):\n",
    "    print(\"INFO> %-15s: %s\" % (key,yamlData[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 500, 768, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                (None, 15, 24, 512)       14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 184320)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               47186176  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                3084      \n",
      "=================================================================\n",
      "Total params: 61,903,948\n",
      "Trainable params: 61,903,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 500, 768, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 500, 768, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 250, 384, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 250, 384, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 250, 384, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 125, 192, 128)     0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 125, 192, 256)     295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 125, 192, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 125, 192, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 62, 96, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 62, 96, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 62, 96, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 62, 96, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 31, 48, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 31, 48, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 31, 48, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 31, 48, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 15, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 184320)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               47186176  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                3084      \n",
      "=================================================================\n",
      "Total params: 61,903,948\n",
      "Trainable params: 61,903,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Look in the tmp directory and select best model candidate based on train/val loss & accuracy\n",
    "nestedModel = tensorflow.keras.models.load_model('/home/jmv/data/mlproj11/tmp/20200412-231005/00011_0.538722_0.904431_0.539206_0.904341.h5')\n",
    "\n",
    "# Flatten the model - this is required in order to use tf_explain\n",
    "# From https://stackoverflow.com/questions/54648296/how-to-flatten-a-nested-model-keras-functional-api\n",
    "def flatten_model(nestedModel):\n",
    "    def get_layers(layers):\n",
    "        layers_flat = []\n",
    "        for layer in layers:\n",
    "            try:\n",
    "                layers_flat.extend(get_layers(layer.layers))\n",
    "            except AttributeError:\n",
    "                layers_flat.append(layer)\n",
    "        return layers_flat\n",
    "\n",
    "    flatModel = tensorflow.keras.models.Sequential(\n",
    "        get_layers(nestedModel.layers)\n",
    "    )\n",
    "    return flatModel\n",
    "\n",
    "nestedModel.summary()\n",
    "model = flatten_model(nestedModel)\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9173 images belonging to 12 classes.\n",
      "{'defect-01': 0, 'defect-02': 1, 'defect-03': 2, 'defect-04': 3, 'defect-05': 4, 'defect-06': 5, 'defect-07': 6, 'defect-08': 7, 'defect-09': 8, 'defect-10': 9, 'defect-11': 10, 'ok': 11}\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0  205]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0   17]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0  103]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0   76]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0   77]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0   38]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0   50]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0   81]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0   67]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0   87]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0   76]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0 8296]]\n",
      "CPU times: user 6min 21s, sys: 1min 3s, total: 7min 25s\n",
      "Wall time: 3min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tstDataGen = tensorflow.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "tstGenerator = tstDataGen.flow_from_directory(\n",
    "    directory=yamlData['tstDir'],\n",
    "    target_size=(yamlData['imageHeight'],yamlData['imageWidth']),\n",
    "    batch_size=1,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "# Confusion matrix\n",
    "predictions = model.predict(tstGenerator)\n",
    "images = tstGenerator.filenames\n",
    "trueClasses = tstGenerator.classes\n",
    "predictedClasses = numpy.argmax(predictions, axis=1)\n",
    "    \n",
    "report = sklearn.metrics.confusion_matrix(trueClasses, predictedClasses)\n",
    "\n",
    "print(tstGenerator.class_indices)\n",
    "print(report)\n",
    "\n",
    "# List images which have a different predicted class vs. true class\n",
    "#for image, trueClass, predictedClass in zip(images,trueClasses,predictedClasses):\n",
    "#    if trueClass!=predictedClass:\n",
    "#        print(\"Image: %s, True Class: %d, Predicted Class: %d\" % (image, trueClass, predictedClass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 500, 768, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 500, 768, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 250, 384, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 250, 384, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 250, 384, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 125, 192, 128)     0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 125, 192, 256)     295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 125, 192, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 125, 192, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 62, 96, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 62, 96, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 62, 96, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 62, 96, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 31, 48, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 31, 48, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 31, 48, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 31, 48, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 15, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 184320)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               47186176  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                3084      \n",
      "=================================================================\n",
      "Total params: 61,903,948\n",
      "Trainable params: 61,903,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "DBG> Desired number of images: 1\n",
      "DBG> Directory to display images from: /home/jmv/data/mlproj11/dataset/tst\n",
      "DBG> Class=defect-01\n",
      "DBG> Full path is /home/jmv/data/mlproj11/dataset/tst/defect-01/sidelight_lamp01_158.jpg\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    /raid5/disk1/tensorflow2/lib/python3.6/site-packages/tf_explain/core/grad_cam.py:106 get_gradients_and_filters  *\n        grad_model = tf.keras.models.Model(\n    /raid5/disk1/tensorflow2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py:146 __init__\n        super(Model, self).__init__(*args, **kwargs)\n    /raid5/disk1/tensorflow2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py:169 __init__\n        self._init_graph_network(*args, **kwargs)\n    /raid5/disk1/tensorflow2/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py:457 _method_wrapper\n        result = method(self, *args, **kwargs)\n    /raid5/disk1/tensorflow2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py:324 _init_graph_network\n        self.inputs, self.outputs)\n    /raid5/disk1/tensorflow2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py:1676 _map_graph_network\n        str(layers_with_complete_input))\n\n    ValueError: Graph disconnected: cannot obtain value for tensor Tensor(\"input_2_6:0\", shape=(None, 500, 768, 3), dtype=float32) at layer \"input_2\". The following previous layers were accessed without issue: ['input_1', 'input_2']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-85136079907c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Call the explainer and save result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmyImageAsArray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"block5_conv3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"grad_cam.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid5/disk1/tensorflow2/lib/python3.6/site-packages/tf_explain/core/grad_cam.py\u001b[0m in \u001b[0;36mexplain\u001b[0;34m(self, validation_data, model, class_index, layer_name, colormap, image_weight)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         outputs, guided_grads = GradCAM.get_gradients_and_filters(\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         )\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid5/disk1/tensorflow2/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid5/disk1/tensorflow2/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    604\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/raid5/disk1/tensorflow2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2360\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid5/disk1/tensorflow2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid5/disk1/tensorflow2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid5/disk1/tensorflow2/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid5/disk1/tensorflow2/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid5/disk1/tensorflow2/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    /raid5/disk1/tensorflow2/lib/python3.6/site-packages/tf_explain/core/grad_cam.py:106 get_gradients_and_filters  *\n        grad_model = tf.keras.models.Model(\n    /raid5/disk1/tensorflow2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py:146 __init__\n        super(Model, self).__init__(*args, **kwargs)\n    /raid5/disk1/tensorflow2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py:169 __init__\n        self._init_graph_network(*args, **kwargs)\n    /raid5/disk1/tensorflow2/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py:457 _method_wrapper\n        result = method(self, *args, **kwargs)\n    /raid5/disk1/tensorflow2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py:324 _init_graph_network\n        self.inputs, self.outputs)\n    /raid5/disk1/tensorflow2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py:1676 _map_graph_network\n        str(layers_with_complete_input))\n\n    ValueError: Graph disconnected: cannot obtain value for tensor Tensor(\"input_2_6:0\", shape=(None, 500, 768, 3), dtype=float32) at layer \"input_2\". The following previous layers were accessed without issue: ['input_1', 'input_2']\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "desiredNumberOfImagesToDisplay = 1\n",
    "dirToDisplayFrom = yamlData['tstDir']  \n",
    "print(f\"DBG> Desired number of images: {desiredNumberOfImagesToDisplay}\")    \n",
    "print(f\"DBG> Directory to display images from: {dirToDisplayFrom}\")    \n",
    "\n",
    "# This line forces the size of the figures\n",
    "matplotlib.pyplot.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "explainer = tf_explain.core.grad_cam.GradCAM()\n",
    "  \n",
    "for myClass in sorted(os.listdir(dirToDisplayFrom)):    \n",
    "    print(f\"DBG> Class={myClass}\")    \n",
    "    listOfImages = [image for image in sorted(os.listdir(os.path.join(dirToDisplayFrom,myClass))) if \"copy\" not in image]\n",
    "    random.shuffle(listOfImages)\n",
    "    actualNumberOfImagesToDisplay = len(listOfImages)    \n",
    "    #print(f\"DBG> Actual number of images: {actualNumberOfImagesToDisplay}\")    \n",
    "    for image in listOfImages[:min(desiredNumberOfImagesToDisplay,actualNumberOfImagesToDisplay)]:      \n",
    "        selectImage = os.path.join(dirToDisplayFrom,myClass,image)    \n",
    "        print(f\"DBG> Full path is {selectImage}\")    \n",
    "        \n",
    "        # Loads an image into PIL format, converts the PIL image into a Numpy array\n",
    "        # Finally, scale the image\n",
    "        myImage = tensorflow.keras.preprocessing.image.load_img(selectImage,target_size=(yamlData['imageHeight'],yamlData['imageWidth']))\n",
    "        myImageAsArray = tensorflow.keras.preprocessing.image.img_to_array(myImage)\n",
    "        myImageAsArray /= 255.0\n",
    "        \n",
    "        # Call the explainer and save result\n",
    "        data = ([myImageAsArray], None)\n",
    "        grid = explainer.explain(validation_data=data, model=model, layer_name=\"block5_conv3\", class_index=4)\n",
    "        explainer.save(grid, \".\", \"grad_cam.png\")\n",
    "        \n",
    "        pil_img = PIL.Image.open(selectImage)    \n",
    "        matplotlib.pyplot.figure()\n",
    "        myImShow = matplotlib.pyplot.imshow(pil_img) \n",
    "        matplotlib.pyplot.title(selectImage,pad=30)  \n",
    "        \n",
    "        pil_img = PIL.Image.open('./grad_cam.png')    \n",
    "        matplotlib.pyplot.figure()\n",
    "        myImShow = matplotlib.pyplot.imshow(pil_img) \n",
    "        matplotlib.pyplot.title(selectImage,pad=30)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(explainer.explain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
